{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame, read_csv\n",
    "# read_csv()\n",
    "import os\n",
    "\n",
    "BLOCK_SIZE = 20\n",
    "FILTER_THRESHOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict\n",
    "\n",
    "\n",
    "# Point = namedtuple('Point',['window', 'snp', 'bp'])\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, snp, bp=0):\n",
    "        self.snp, self.bp = snp, bp\n",
    "    \n",
    "    @property\n",
    "    def window(self):\n",
    "        return self.snp // BLOCK_SIZE\n",
    "\n",
    "# class Specimen:\n",
    "#     def __init__(self, ident, sequence)\n",
    "#         ident, sequence\n",
    "    \n",
    "class Node:\n",
    "    def __init__(self, ident, start, end):\n",
    "        self.id = ident\n",
    "        self.start = start #Point()\n",
    "        self.end = end #Point()\n",
    "        self.upstream = defaultdict(lambda: 0)  # {nothing_node:501, Node: 38,  Node: 201, Node: 3}\n",
    "        self.downstream = defaultdict(lambda: 0) # {Node: 38,  Node: 201, Node: 3}\n",
    "        self.specimens = set()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.specimens)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"N%s(%s, %s)\" % (str(self.id), str(self.start.snp), str(self.end.snp))\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.id) + hash(self.start.snp) + hash(self.end.snp)\n",
    "    \n",
    "#     def details(self):\n",
    "        \n",
    "\n",
    "a = Point(0)\n",
    "b = Point(14)\n",
    "str(Node(57, a, b))\n",
    "nothing_node = Node(-1, Point(None), Point(None))\n",
    "global_nodes = {0: nothing_node}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path = \"../test_data/KE_chromo10.txt\"):\n",
    "    \"\"\"Individuals are rows, not columns\"\"\"\n",
    "    loci = []\n",
    "    with open(file_path) as ke:\n",
    "        for line in ke.readlines():\n",
    "            loci.append(tuple(int(x) for x in line.split()))\n",
    "            \n",
    "    \n",
    "    individuals = np.array(loci).T.tolist()\n",
    "    return loci, individuals\n",
    "alleles, individuals = read_data()\n",
    "assert len(alleles) == 32767\n",
    "assert len(individuals[1]) == 32767\n",
    "assert len(individuals) == 501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first(iterable):\n",
    "    return next(iter(iterable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0): N0(0, 0),\n",
       " (0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2): N1(0, 0),\n",
       " (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0): N2(0, 0),\n",
       " (2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2): N3(0, 0)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def signature(individual, start_locus):\n",
    "    return tuple(individual[start_locus : start_locus + BLOCK_SIZE])\n",
    "\n",
    "def get_unique_signatures(individuals, start_locus, block_size = 20):\n",
    "    unique_blocks = {}\n",
    "    for individual in individuals:\n",
    "        sig = signature(individual, start_locus)\n",
    "        if sig not in unique_blocks:\n",
    "            unique_blocks[sig] = Node(len(unique_blocks), Point(start_locus // block_size, start_locus), \n",
    "                                      Point(start_locus // block_size, start_locus + BLOCK_SIZE)) #TODO: -1?\n",
    "    \n",
    "    return unique_blocks\n",
    "unique_blocks = get_unique_signatures(individuals, 0 )\n",
    "    \n",
    "assert len(unique_blocks) == 4\n",
    "unique_blocks\n",
    "# assert unique_blocks == {(0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0): 0,\n",
    "#  (0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2): 1,\n",
    "#  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0): 2,\n",
    "#  (2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2): 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_signatures(alleles, individuals):\n",
    "    unique_signatures = []\n",
    "    for locus_start in range(0, len(alleles) - BLOCK_SIZE, BLOCK_SIZE):  # discards remainder \n",
    "        sig = get_unique_signatures(individuals, locus_start, BLOCK_SIZE)\n",
    "        unique_signatures.append(sig)\n",
    "    return unique_signatures\n",
    "unique_signatures = get_all_signatures(alleles, individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2): N0(21, 21),\n",
       " (0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2): N1(21, 21),\n",
       " (0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0): N2(21, 21),\n",
       " (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0): N3(21, 21),\n",
       " (0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0): N4(21, 21),\n",
       " (0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2): N5(21, 21),\n",
       " (0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0): N6(21, 21),\n",
       " (0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2): N7(21, 21)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_signatures[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[N2(0, 0), N2(1, 1), N2(2, 2), N2(3, 3), N2(4, 4), N2(5, 5), N3(6, 6), N3(7, 7), N3(8, 8), N2(9, 9), N0(10, 10), N1(11, 11), N2(12, 12), N2(13, 13), N2(14, 14), N2(15, 15), N3(16, 16), N3(17, 17), N4(18, 18), N3(19, 19), N5(20, 20), N3(21, 21), N3(22, 22), N10(23, 23), N4(24, 24), N3(25, 25), N4(26, 26), N3(27, 27), N1(28, 28), N1(29, 29), N4(30, 30), N3(31, 31), N21(32, 32), N1(33, 33), N1(34, 34), N1(35, 35), N1(36, 36), N1(37, 37), N1(38, 38), N1(39, 39), N1(40, 40), N1(41, 41), N1(42, 42), N1(43, 43), N1(44, 44), N1(45, 45), N1(46, 46), N1(47, 47), N1(48, 48), N1(49, 49), N1(50, 50), N1(51, 51), N1(52, 52), N1(53, 53), N1(54, 54), N1(55, 55), N1(56, 56), N1(57, 57), N1(58, 58), N1(59, 59), N1(60, 60), N1(61, 61), N1(62, 62), N1(63, 63), N1(64, 64), N1(65, 65), N1(66, 66), N1(67, 67), N1(68, 68), N1(69, 69), N1(70, 70), N1(71, 71), N1(72, 72), N1(73, 73), N1(74, 74), N1(75, 75), N1(76, 76), N1(77, 77), N0(78, 78), N0(79, 79), N1(80, 80), N1(81, 81), N1(82, 82), N1(83, 83), N1(84, 84), N1(85, 85), N1(86, 86), N1(87, 87), N1(88, 88), N1(89, 89), N1(90, 90), N1(91, 91), N1(92, 92), N1(93, 93), N1(94, 94), N1(95, 95), N1(96, 96), N1(97, 97), N0(98, 98), N0(99, 99)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(501, 1638)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_individuals(individuals, unique_signatures):\n",
    "    simplified_individuals = []\n",
    "    for i_specimen, specimen in enumerate(individuals):\n",
    "        my_simplification = []\n",
    "        for w, window in enumerate(unique_signatures):  # the length of the genome\n",
    "            sig = signature(specimen, w * BLOCK_SIZE)\n",
    "    #         print(sig, unique_signatures[w][sig])\n",
    "    #         print(i_specimen, window)\n",
    "            my_simplification.append(unique_signatures[w][sig])\n",
    "        simplified_individuals.append(my_simplification)\n",
    "    return simplified_individuals\n",
    "simplified_individuals = build_individuals(individuals, unique_signatures)\n",
    "print(simplified_individuals[500][:100])\n",
    "len(simplified_individuals), len(simplified_individuals[60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes: Populate upstream and downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build nodes:  first 4 are the 4 starting signatures in window 0.  \n",
    "# For each node list which individuals are present at that node\n",
    "# List transition rates from one node to all other upstream and downstream\n",
    "def populate_transitions(simplified_individuals):\n",
    "    for i, indiv in enumerate(simplified_individuals):\n",
    "        # look what variants are present\n",
    "        for x, node in enumerate(indiv):\n",
    "            node.specimens.add(i)\n",
    "            if x + 1 < len(indiv):\n",
    "                node.downstream[indiv[x+1]] += 1\n",
    "            else:\n",
    "                node.downstream[nothing_node] += 1\n",
    "            if x-1 >= 0:\n",
    "                node.upstream[indiv[x-1]] += 1\n",
    "            else: \n",
    "                node.upstream[nothing_node] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_signatures = get_all_signatures(alleles, individuals)\n",
    "simplified_individuals = build_individuals(individuals, unique_signatures)\n",
    "populate_transitions(simplified_individuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: turn these into tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Node.__init__.<locals>.<lambda>()>,\n",
       "            {N1(1, 1): 286})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_individuals[50][0].downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Node.__init__.<locals>.<lambda>()>,\n",
       "            {N0(1, 1): 103})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_individuals[49][0].downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Node.__init__.<locals>.<lambda>()>,\n",
       "            {N2(1, 1): 82})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_individuals[500][0].downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Node.__init__.<locals>.<lambda>()>,\n",
       "            {N1(1, 1): 30})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_individuals[91][0].downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_values([299]), dict_values([120]), dict_values([82])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.downstream.values() for x in unique_signatures[1000].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_values([102, 197]), dict_values([120]), dict_values([82])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.upstream.values() for x in unique_signatures[1000].values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add signature directly to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blist import blist\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_no_duplicate_nodes(global_nodes):\n",
    "    unique_nodes = set()\n",
    "    for node in global_nodes:\n",
    "        if node in unique_nodes:\n",
    "            print(node)\n",
    "        else:\n",
    "            unique_nodes.add(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom_stack = [[]]\n",
    "def simple_merge(global_nodes):\n",
    "    new_layer = []  # TODO: copy old nodes to new layer conditionally\n",
    "    n = 0\n",
    "    while n < len(global_nodes):  # size of global_nodes changes, necessitating this weird loop\n",
    "        node = global_nodes[n]\n",
    "    #     print(node, type(node))\n",
    "        if len(node.downstream) == 1: \n",
    "            next_node = first(node.downstream.keys())\n",
    "            if len(node.specimens) == len(next_node.specimens):\n",
    "                #Torsten deletes nodeA and modifies next_node\n",
    "                next_node.upstream = node.upstream\n",
    "                next_node.start = node.start\n",
    "                #prepare to delete node by removing references\n",
    "                for parent in node.upstream.keys():\n",
    "                    if parent != nothing_node:\n",
    "                        count = parent.downstream[node]\n",
    "                        del parent.downstream[node]  # updating pointer \n",
    "                        parent.downstream[next_node] = count \n",
    "                global_nodes.remove(node)  #delete node\n",
    "                # zoom_stack[0].append(merged)\n",
    "                n -= 1\n",
    "        n += 1\n",
    "    return global_nodes        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simple_merge():\n",
    "    global_nodes = blist([node for window in unique_signatures for node in window.values()])  # think about referencing and deletion\n",
    "    assert len(global_nodes) == 7180\n",
    "    summary1 = simple_merge(global_nodes)\n",
    "    assert len(summary1) == 3690\n",
    "    return summary1\n",
    "summary1 = test_simple_merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neglect Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_node(node):\n",
    "    \"\"\"Changes references to this node to add to references to nothing_node\"\"\"\n",
    "    for parent, count in node.upstream.items():\n",
    "        parent.downstream[nothing_node] += parent.downstream[node]\n",
    "        del parent.downstream[node]\n",
    "    for descendant, count in node.downstream.items():\n",
    "        descendant.upstream[nothing_node] += descendant.upstream[node]\n",
    "        del descendant.upstream[node]\n",
    "        \n",
    "\n",
    "def neglect_nodes(all_nodes):\n",
    "    nodes_to_delete = set()\n",
    "#     filtered_nodes = copy(all_nodes)\n",
    "#     filtered_nodes.remove(1)\n",
    "#     assert len(all_nodes) != len(filtered_nodes)\n",
    "    for node in all_nodes:\n",
    "        if len(node.specimens) < FILTER_THRESHOLD:\n",
    "            delete_node(node)  # TODO: check if this will orphan \n",
    "            nodes_to_delete.add(node)\n",
    "    filtered_nodes = blist([x for x in all_nodes if x not in nodes_to_delete])\n",
    "    # TODO: remove orphaned haplotypes in a node that transition to and from zero within a 10 window length\n",
    "    return filtered_nodes \n",
    "\n",
    "\n",
    "def test_neglect_nodes(all_nodes):\n",
    "    summary2 = neglect_nodes(all_nodes)\n",
    "    assert len(summary2) == 2854\n",
    "    return summary2\n",
    "summary2 = test_neglect_nodes(summary1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-52-3a240befdc8c>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-52-3a240befdc8c>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    new.upstream[nothing_node] = len(new.specimens) - #Whatever is in all others keys together\u001b[0m\n\u001b[1;37m                                                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def split_one_group(prev_node, anchor, next_node):\n",
    "    \"\"\" Called when up.specimens == down.specimens\"\"\"\n",
    "    new = Node(777, prev_node.start, next_node.end, prev_node.upstream, next_node.downstream)  # TODO: what about case where more content is joining downstream?\n",
    "    # Comment: That is actually the case we want to split up to obtain longer blocks later\n",
    "    # Extension of full windows will take care of potential loss of information later\n",
    "    \n",
    "    if nothing_node != prev_node:\n",
    "        new.specimens = anchor.specimens.intersection(prev_node.specimens)\n",
    "    elif nothing_node != next_node:\n",
    "        new.specimens = anchor.specimens.intersection(next_node.specimens)\n",
    "    else:\n",
    "        new.specimens = anchor.specimens\n",
    "        for n in new.downstream.keys():\n",
    "            if n != nothing_node:\n",
    "                new.specimens = new.specimens.remove(n.specimens)\n",
    "        for n in new.upstream.keys():\n",
    "            if n != nothing_node:\n",
    "                new.specimens = new.specimens.remove(n.specimens)\n",
    "    \n",
    "    if nothing_node == prev_node:\n",
    "        new.start = anchor.start\n",
    "        new.upstream = anchor.upstream\n",
    "    if nothing_node is next_node:\n",
    "        new.end = anchor.end\n",
    "        new.downstream = anchor.downstream\n",
    "    \n",
    "    # Update upstream/downstream\n",
    "    for n in new.upstream.keys():\n",
    "        if n != nothing_node:\n",
    "            new.upstream[n] = len(new.specimens.intersection(n.specimens))\n",
    "            n.downstream[new] = new.upstream[n]\n",
    "            n.downstream[prev_node] = n.downstream[prev_node] - n.downstream[new]\n",
    "            if n.downstream[prev_node] == 0:\n",
    "                del n.downstream[prev_node]\n",
    "\n",
    "    for n in new.downstream.keys():\n",
    "        if n != nothing_node:\n",
    "            new.downstream[n] = len(new.specimens.intersection(n.specimens))\n",
    "            n.upstream[new] = new.downstream[n]\n",
    "            n.upstream[prev_node] = n.upstream[prev_node] - n.upstream[new]\n",
    "            if n.upstream[prev_node] == 0:\n",
    "                del n.upstream[prev_node]\n",
    "                \n",
    "    new.upstream[nothing_node] = len(new.specimens) - #Whatever is in all others keys together\n",
    "    new.downstream[nothing_node] = len(new.specimens) - # whatever is in all others keys together\n",
    "    if new.upstream[nothing_node] == 0:\n",
    "        del new.upstream[nothing_node]\n",
    "    \n",
    "    if new.downstream[nothing_node] == 0:\n",
    "        del new.downstream[nothing_node]\n",
    "    \n",
    "    # Update Specimens in prev_node, anchor, next_node\n",
    "    if prev_node != nothing_node:\n",
    "        prev_node.specimens = prev_node.specimens.remove(new.specimens)\n",
    "    \n",
    "    if next_node != nothing_node:\n",
    "        next_node.specimens = next_node.specimens.remove(new.specimens)\n",
    "    \n",
    "    anchor.specimens = anchor.specimens.remove(new.specimens)\n",
    "        \n",
    "    ## anchor.specimens.difference_update(prev_node.specimens) REASON?\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'split_one_group' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-5e7d8ce5e575>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_split_one_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownstream\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-5e7d8ce5e575>\u001b[0m in \u001b[0;36mtest_split_one_group\u001b[1;34m(prev_node, anchor, next_node)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_split_one_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_one_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m'14  16  19  20  28  56  59  69  88 133 140 155 159 160 175 193 199 201 224 249 252 258 260 267 268 283 292 295 318 322 325 332 341 344 346 351 354 357 362 364 367 373 374 375 381 386 392 393 394 402 403 417 421 424 426 431 434 435 438 442 445 447 452 455 457 462 463 464 467 471 473 475 476 477 478 480 483 484 494 497 501'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split_one_group' is not defined"
     ]
    }
   ],
   "source": [
    "test_graph = summary2  # deepcopy(\n",
    "example = test_graph[7]\n",
    "# original = deepcopy(example)\n",
    "print(len(example))\n",
    "def test_split_one_group(prev_node, anchor, next_node):\n",
    "    x = split_one_group(prev_node, anchor, next_node)\n",
    "    assert x\n",
    "    answer = set(int(x)-1 for x in '14  16  19  20  28  56  59  69  88 133 140 155 159 160 175 193 199 201 224 249 252 258 260 267 268 283 292 295 318 322 325 332 341 344 346 351 354 357 362 364 367 373 374 375 381 386 392 393 394 402 403 417 421 424 426 431 434 435 438 442 445 447 452 455 457 462 463 464 467 471 473 475 476 477 478 480 483 484 494 497 501'.split())\n",
    "    assert x.specimens == answer, 'Specimens set does not agree with HaploBlocker' + str(x.specimens.difference(answer))\n",
    "    return x\n",
    "\n",
    "x = test_split_one_group(first(example.upstream),  example, first(example.downstream) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_groups(all_nodes):\n",
    "    \"\"\"This is called crossmerge in the R code\"\"\"\n",
    "    n = 0\n",
    "    number_of_windows = len(first(simplified_individuals))\n",
    "    while n < len(all_nodes):  # size of global_nodes changes, necessitating this weird loop\n",
    "        node = all_nodes[n]\n",
    "        #check if all transitition upstream match with one of my downstream nodes\n",
    "        if set(node.upstream.values()) == set(node.downstream.values()):\n",
    "            if node.start.snp != 0 and node.end.window != number_of_windows: #chr begin or end\n",
    "                if len(node.specimens) > 0:\n",
    "                    # Matchup upstream and downstream with specimen identities\n",
    "                    for up in node.upstream:\n",
    "                        for down in node.downstream:\n",
    "                            if up.specimens == down.specimens:\n",
    "                                new_node = split_one_group(up, node, down)\n",
    "                    if not node.specimens:  \n",
    "                        # all content has been moved\n",
    "                        all_nodes.remove(node)\n",
    "                        n -= 1\n",
    "        n += 1\n",
    "    return all_nodes\n",
    "    \n",
    "\n",
    "def test_split_groups(all_nodes):\n",
    "    summary3 = split_groups(all_nodes)\n",
    "    assert summary3\n",
    "    return summary3\n",
    "summary3 = test_split_groups(summary2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Test if split_groups() is working now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-3a8fada85652>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "len(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class '__main__.Node'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "N3(5, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(example), type(example))\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example.specimens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'defaultdict(<function Node.__init__.<locals>.<lambda> at 0x000001D9A869B730>, {})'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.upstream.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Node.__init__.<locals>.<lambda>()>,\n",
       "            {N3(8, 8): 81})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Node.__init__.<locals>.<lambda>()>,\n",
       "            {N3(5, 6): 81, N-1(None, None): 1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(example.upstream).downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2): N0(0, 1),\n",
       " (2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0): N1(1, 1),\n",
       " (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0): N2(0, 1)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_signatures[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N2(0, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = first(example.upstream)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "set().difference_update({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Node.__init__.<locals>.<lambda>()>,\n",
       "            {N1(6, 6): 155, N2(6, 6): 158, N-1(None, None): 2})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary1[4].downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
